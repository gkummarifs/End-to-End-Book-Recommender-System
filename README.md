# End-to-End-Book-Recommender-System
üìö End-to-End Book Recommender System (KNN-Based)

I built this End-to-End Book Recommender System to demonstrate how a classical machine-learning approach (K-Nearest Neighbors) can be used to solve a real-world recommendation problem from scratch ‚Äî covering data preprocessing, model training, similarity search, and inference in a clean, reproducible way.

Rather than relying on black-box deep learning models, this project focuses on interpretable, scalable, and production-friendly recommendation logic, which is still widely used in real systems for personalization and discovery.

üéØ What This Project Does

This system recommends books by identifying similar books based on user interaction patterns using a Nearest Neighbor‚Äìbased collaborative filtering approach.

At a high level, the system:

Processes raw book and user-rating data

Transforms it into a structured user‚Äìitem matrix

Uses a K-Nearest Neighbors (KNN) model to learn similarity relationships

Finds books that are closest (most similar) to a given input book

Returns relevant recommendations based on learned proximity

The result is a fast, explainable recommendation pipeline that works well even with sparse datasets.

üß† Why I Built This

Many recommendation systems tutorials jump directly to complex deep-learning solutions.
In practice, however:

KNN-based recommenders are widely used due to their simplicity and effectiveness

They are easier to debug, interpret, and iterate on

They provide strong baselines for personalization problems

This project was built to clearly demonstrate the fundamentals of recommender systems while still being realistic, structured, and extensible for real-world use.

üîç Core Machine Learning Approach
Nearest Neighbor Recommendation (Collaborative Filtering)

Uses K-Nearest Neighbors to measure similarity between books

Similarity is derived from user rating behavior

Books with similar interaction patterns are considered ‚Äúneighbors‚Äù

Recommendations are generated by selecting the closest neighbors in feature space

This approach allows the system to:

Capture implicit user preferences

Recommend books without needing deep content understanding

Scale efficiently for medium-sized datasets

üõ† Project Components & Architecture

This repository is organized to reflect a real ML workflow:

Data ingestion & preprocessing

Cleaning and structuring raw datasets

Creating a user‚Äìitem interaction matrix

Feature engineering

Transforming ratings into numerical representations

Handling sparsity and normalization

Model training

Training a KNN model using distance-based similarity

Optimizing neighbor selection

Recommendation logic

Identifying nearest neighbors for a given book

Returning ranked recommendations

Inference pipeline

Accepting a book as input

Producing similar book suggestions

Each step is modular and can be independently improved or replaced.

üß™ Why KNN Was a Deliberate Choice

I intentionally chose K-Nearest Neighbors because it:

Provides transparent and explainable recommendations

Performs well for collaborative filtering tasks

Requires minimal hyperparameter tuning

Serves as a strong baseline for more advanced systems

Mirrors approaches still used in production recommendation engines

This makes the project both educational and practical.

üíº What This Demonstrates to Hiring Managers

This project showcases my ability to:

Build an end-to-end ML system, not just a model

Apply classical ML algorithms effectively

Work with real datasets and sparse data

Design clean, modular ML pipelines

Think about scalability, interpretability, and maintainability

It reflects a solid understanding of recommendation system fundamentals, which are critical even in modern AI-driven products.

üöÄ Possible Extensions

This system can be extended with:

Content-based features (book descriptions, genres)

Hybrid recommendation strategies

Real-time user feedback integration

API or UI layer (e.g., Streamlit)

Model evaluation metrics (precision@k, recall@k)

‚úÖ Summary

This project demonstrates how a Nearest Neighbor‚Äìbased recommendation system can be built end-to-end using sound machine-learning principles. It focuses on clarity, correctness, and real-world applicability, making it a strong foundation for more advanced recommender systems.

##Technical details:

## Workflow

- config.yaml
- entity
- config/configuration.py
- components
- pipeline
- main.py
- app.py


# How to run?
### STEPS:

Clone the repository

```bash
https://github.com/entbappy/End-to-End-Book-Recommender-System.git
```
### STEP 01- Create a conda environment after opening the repository

```bash
conda create -n books python=3.7.10 -y
```

```bash
conda activate books
```


### STEP 02- install the requirements
```bash
pip install -r requirements.txt
```


Now run,
```bash
streamlit run app.py
```


# Streamlit app Docker Image Deployment

## 1. Login with your AWS console and launch an EC2 instance
## 2. Run the following commands

Note: Do the port mapping to this port:- 8501

```bash
sudo apt-get update -y

sudo apt-get upgrade

#Install Docker

curl -fsSL https://get.docker.com -o get-docker.sh

sudo sh get-docker.sh

sudo usermod -aG docker ubuntu

newgrp docker
```

```bash
git clone "your-project"
```

```bash
docker build -t entbappy/stapp:latest . 
```

```bash
docker images -a  
```

```bash
docker run -d -p 8501:8501 entbappy/stapp 
```

```bash
docker ps  
```

```bash
docker stop container_id
```

```bash
docker rm $(docker ps -a -q)
```

```bash
docker login 
```

```bash
docker push entbappy/stapp:latest 
```

```bash
docker rmi entbappy/stapp:latest
```

```bash
docker pull entbappy/stapp
```







